{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a04101",
   "metadata": {},
   "source": [
    "# [Memory](https://langchain-ai.github.io/langgraph/concepts/memory/)\n",
    "- LangGraph의 Memory는 AI가 대화 내용을 기억할 수 있게 해주는 기능입니다. \n",
    "- 사람이 대화할 때 이전에 말한 내용을 기억하는 것처럼, AI도 과거 대화를 기억해서 더 자연스러운 대화를 할 수 있게 해줍니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7436e108",
   "metadata": {},
   "source": [
    "## 왜 Memory가 필요한가요?\n",
    "> Memory가 없다면:\n",
    "```text\n",
    "    사용자: \"내 이름은 김철수야\"\n",
    "    AI: \"안녕하세요!\"\n",
    "\n",
    "    사용자: \"내 이름이 뭐였지?\"\n",
    "    AI: \"죄송해요, 모르겠습니다\"\n",
    "```\n",
    "> Memory가 있다면:\n",
    "```text\n",
    "    사용자: \"내 이름은 김철수야\"\n",
    "    AI: \"안녕하세요 김철수님!\"\n",
    "\n",
    "    사용자: \"내 이름이 뭐였지?\"\n",
    "    AI: \"김철수님이라고 하셨어요!\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30e362",
   "metadata": {},
   "source": [
    "# ConversationSummaryMemory 예시\n",
    "**오래된 대화를 요약해서 기억하는 똑똑한 챗봇**\n",
    "\n",
    "모든 대화를 기억하되, 오래된 내용은 요약해서 저장하는 방법입니다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57045bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d0e99",
   "metadata": {},
   "source": [
    "### 1. AI 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3213aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea765aaa",
   "metadata": {},
   "source": [
    "### 2. 요약 기능이 포함된 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f1395ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def summarize_old_messages(messages, max_messages=4):\n",
    "    \"\"\"오래된 메시지들을 요약하는 함수\"\"\"\n",
    "    if len(messages) <= max_messages:\n",
    "        return messages\n",
    "    \n",
    "    # 오래된 메시지와 최근 메시지 분리\n",
    "    old_messages = messages[:-max_messages]\n",
    "    recent_messages = messages[-max_messages:]\n",
    "    \n",
    "    # 요약 만들기\n",
    "    summary_text = \"이전 대화 요약:\\\\n\"\n",
    "    for msg in old_messages:\n",
    "        if msg.type == \"human\":\n",
    "            summary_text += f\"- 사용자: {msg.content}\\\\n\"\n",
    "        elif msg.type == \"ai\":\n",
    "            summary_text += f\"- AI: {msg.content}\\\\n\"\n",
    "    \n",
    "    # 요약을 시스템 메시지로 만들기\n",
    "    summary_message = SystemMessage(content=summary_text)\n",
    "    \n",
    "    return [summary_message] + recent_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4a5afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "def chat_node_with_summary(state: MessagesState):\n",
    "    # 메시지가 너무 많으면 요약\n",
    "    summarized_messages = summarize_old_messages(state[\"messages\"])\n",
    "    \n",
    "    response = llm.invoke(summarized_messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5ef2d",
   "metadata": {},
   "source": [
    "### 3. 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d982a61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11549eea0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END \n",
    "\n",
    "graph_summary = StateGraph(MessagesState)\n",
    "graph_summary.add_node(\"chat\", chat_node_with_summary)\n",
    "graph_summary.add_edge(START, \"chat\")\n",
    "graph_summary.add_edge(\"chat\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be058b",
   "metadata": {},
   "source": [
    "### 4. 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48971994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Memory 챗봇이 준비되었습니다! (오래된 대화는 요약해서 기억)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory_summary = MemorySaver()\n",
    "app_with_summary = graph_summary.compile(checkpointer=memory_summary)\n",
    "\n",
    "print(\"Summary Memory 챗봇이 준비되었습니다! (오래된 대화는 요약해서 기억)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5259f",
   "metadata": {},
   "source": [
    "### 5. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c014747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary Memory 챗봇 테스트 ===\n",
      "많은 정보를 말해보고, 나중에 요약된 정보로 기억하는지 확인해보겠습니다!\\n\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "# 중요: 같은 thread_id를 사용해야 대화가 연결됩니다!\n",
    "memory_id = str(uuid.uuid4())\n",
    "# Summary Memory 테스트\n",
    "config_summary = {\"configurable\": {\"thread_id\": memory_id}}\n",
    "\n",
    "print(\"=== Summary Memory 챗봇 테스트 ===\")\n",
    "print(\"많은 정보를 말해보고, 나중에 요약된 정보로 기억하는지 확인해보겠습니다!\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900b15a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 대화: '내 이름은 김철수야'\n",
      "AI: 안녕하세요, 김철수님! 어떻게 도와드릴까요?\n",
      "----------------------------------------\n",
      "2번째 대화: '나는 서울에 살아'\n",
      "AI: 서울에 사시는군요! 서울은 정말 다양한 문화와 매력이 있는 도시죠. 서울에서 좋아하는 장소나 활동이 있으신가요?\n",
      "----------------------------------------\n",
      "3번째 대화: '취미는 축구야'\n",
      "AI: 축구를 좋아하시군요! 축구는 정말 재미있고 팀워크도 중요한 스포츠죠. 어떤 팀을 응원하시나요? 또는 자주 축구를 하시나요?\n",
      "----------------------------------------\n",
      "4번째 대화: '좋아하는 음식은 피자야'\n",
      "AI: 피자를 좋아하시군요! 피자는 다양한 토핑과 스타일로 즐길 수 있어서 정말 매력적인 음식이죠. 어떤 종류의 피자를 가장 좋아하시나요? 마르게리타, 페퍼로니, 아니면 다른 특별한 토핑이 있나요?\n",
      "----------------------------------------\n",
      "5번째 대화: '오늘 날씨가 좋네'\n",
      "AI: 날씨가 좋다니 기분이 좋으시겠어요! 이렇게 좋은 날에는 밖에 나가서 활동하기 좋은 것 같아요. 혹시 오늘 특별한 계획이 있으신가요?\n",
      "----------------------------------------\n",
      "6번째 대화: '좋아하는 과일은 수박,복숭아야'\n",
      "AI: 수박과 복숭아를 좋아하시군요! 여름철에 특히 맛있는 과일들이죠. 수박은 시원하고 상큼해서 더위를 식히기에 좋고, 복숭아는 달콤하고 부드러워서 정말 맛있죠. 두 과일을 함께 먹으면 더 맛있을 것 같아요! 과일을 자주 드시나요?\n",
      "----------------------------------------\n",
      "7번째 대화: '내 이름과 사는 곳이 뭐였지?'\n",
      "AI: 당신의 이름은 김철수님이고, 서울에 사신다고 하셨습니다!\n",
      "----------------------------------------\n",
      "\\n결과: 오래된 대화는 요약되지만 중요한 정보는 기억합니다!\n",
      "메모리 효율적이면서도 핵심 정보를 유지해요!\n"
     ]
    }
   ],
   "source": [
    "# 테스트할 메시지들\n",
    "test_messages = [\n",
    "    \"내 이름은 김철수야\",\n",
    "    \"나는 서울에 살아\", \n",
    "    \"취미는 축구야\",\n",
    "    \"좋아하는 음식은 피자야\",\n",
    "    \"오늘 날씨가 좋네\",\n",
    "    \"좋아하는 과일은 수박,복숭아야\",\n",
    "    \"내 이름과 사는 곳이 뭐였지?\"  # 오래된 정보가 요약되어 기억되는지 테스트\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(test_messages, 1):\n",
    "    print(f\"{i}번째 대화: '{msg}'\")\n",
    "    result = app_with_summary.invoke(\n",
    "        {\"messages\": [HumanMessage(content=msg)]}, \n",
    "        config=config_summary\n",
    "    )\n",
    "    print(f\"AI: {result['messages'][-1].content}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\\\n결과: 오래된 대화는 요약되지만 중요한 정보는 기억합니다!\")\n",
    "print(\"메모리 효율적이면서도 핵심 정보를 유지해요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80b5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
