{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f53d977",
   "metadata": {},
   "source": [
    "# pgvector VectorDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444468d4",
   "metadata": {},
   "source": [
    "## 1. pgvector란?\n",
    "\n",
    "pgvector는 PostgreSQL 데이터베이스에 벡터 유사도 검색 기능을 추가하는 오픈소스 확장입니다.\n",
    "\n",
    "### 주요 특징\n",
    "- **PostgreSQL 기반**: 기존 관계형 데이터베이스에 벡터 검색 기능 추가\n",
    "- **ACID 보장**: 트랜잭션의 원자성, 일관성, 격리성, 지속성 보장\n",
    "- **SQL 인터페이스**: 표준 SQL을 사용하여 벡터 검색 수행\n",
    "- **확장성**: 대용량 데이터 처리에 적합한 PostgreSQL의 확장성 활용\n",
    "- **LangChain 통합**: LangChain과 완벽하게 통합되어 RAG 시스템 구축 가능\n",
    "\n",
    "### 사용 사례\n",
    "- 기존 PostgreSQL 기반 시스템에 벡터 검색 기능 추가\n",
    "- 대규모 RAG 시스템 구축\n",
    "- 하이브리드 검색 (키워드 + 벡터 검색)\n",
    "- 엔터프라이즈급 벡터 데이터베이스 솔루션\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc4948",
   "metadata": {},
   "source": [
    "## 2. pgvector vs 다른 벡터 데이터베이스\n",
    "\n",
    "### pgvector의 장점\n",
    "- **기존 인프라 활용**: PostgreSQL이 이미 구축된 환경에서 추가 설정 없이 사용\n",
    "- **데이터 일관성**: 관계형 데이터와 벡터 데이터를 동일한 트랜잭션에서 처리\n",
    "- **복잡한 쿼리**: SQL의 강력한 기능을 활용한 복합 검색 가능\n",
    "- **백업 및 복구**: PostgreSQL의 검증된 백업/복구 시스템 활용\n",
    "- **보안**: PostgreSQL의 강력한 보안 기능 활용\n",
    "\n",
    "### 다른 솔루션과의 비교\n",
    "- **Chroma**: 간단한 설정, 메모리 기반, 소규모 프로젝트에 적합\n",
    "- **Milvus**: 대규모 분산 환경, 높은 성능, 복잡한 설정\n",
    "- **pgvector**: 기존 DB 활용, 중간 규모, 엔터프라이즈 환경\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c54a6",
   "metadata": {},
   "source": [
    "## 3. 설치 및 설정\n",
    "\n",
    "pgvector를 사용하기 위한 설치와 설정 방법을 알아보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad2b030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요한 라이브러리가 import되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# !pip install pgvector psycopg2-binary langchain langchain-community\n",
    "\n",
    "# 기본 라이브러리 import\n",
    "import os\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from langchain.vectorstores import PGVector\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "print(\"필요한 라이브러리가 import되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4ac7f",
   "metadata": {},
   "source": [
    "### PostgreSQL 설정\n",
    "\n",
    "pgvector를 사용하려면 PostgreSQL 데이터베이스에 pgvector 확장을 설치해야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719d7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    database=\"vectordb\",\n",
    "    user=\"admin\",\n",
    "    password=\"admin123\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f068b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터베이스 연결 및 pgvector 확장 활성화\n",
    "def setup_pgvector_extension(connection_string):\n",
    "    \"\"\"PostgreSQL에 pgvector 확장을 설치하고 활성화\"\"\"\n",
    "    try:\n",
    "        # 데이터베이스 연결\n",
    "        conn = psycopg2.connect(connection_string)\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # pgvector 확장 설치 (이미 설치되어 있다면 무시됨)\n",
    "        cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "        \n",
    "        # 벡터 타입 등록\n",
    "        register_vector(conn)\n",
    "        \n",
    "        print(\"pgvector 확장이 성공적으로 설치되었습니다.\")\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"pgvector 설정 중 오류 발생: {e}\")\n",
    "        print(\"PostgreSQL이 실행 중이고 연결 정보가 올바른지 확인하세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a276614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgvector 확장이 성공적으로 설치되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# PostgreSQL 연결 설정\n",
    "# 실제 환경에서는 환경변수나 설정 파일을 사용하세요\n",
    "# \"postgresql://아이디:비밀번호@localhost:5432/데이터베이스명\"\n",
    "CONNECTION_STRING = \"postgresql://admin:admin123@localhost:5432/vectordb\"\n",
    "\n",
    "# 실제 사용시에는 아래 주석을 해제하세요\n",
    "setup_pgvector_extension(CONNECTION_STRING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3a8eb",
   "metadata": {},
   "source": [
    "## 4. LangChain과 pgvector 연결\n",
    "LangChain의 PGVector 클래스를 사용하여 PostgreSQL과 연결하는 방법을 알아보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d6ae7",
   "metadata": {},
   "source": [
    "### CustomPGVector\n",
    "- 이미 만들어진 테이블 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e16b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "\n",
    "class CustomPGVector(VectorStore):\n",
    "    def __init__(self, conn_str: str, embedding_fn, table: str = \"my_vectors\"):\n",
    "        self.conn = psycopg2.connect(conn_str)\n",
    "        self.embedding_fn = embedding_fn\n",
    "        self.table = table\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(\n",
    "        cls,\n",
    "        texts: List[str],\n",
    "        embedding_fn,\n",
    "        metadatas: Optional[List[Dict[str, Any]]] = None,\n",
    "        conn_str: str = None,\n",
    "        table: str = \"my_vectors\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        store = cls(conn_str=conn_str, embedding_fn=embedding_fn, table=table)\n",
    "        store.add_texts(texts, metadatas=metadatas)\n",
    "        return store\n",
    "\n",
    "    def add_texts(self, texts: List[str], metadatas: List[Dict[str, Any]] = None):\n",
    "        metadatas = metadatas or [{} for _ in texts]\n",
    "        embeddings = self.embedding_fn.embed_documents(texts)\n",
    "\n",
    "        with self.conn.cursor() as cur:\n",
    "            for text, emb, meta in zip(texts, embeddings, metadatas):\n",
    "                cur.execute(\n",
    "                    f\"\"\"\n",
    "                    INSERT INTO {self.table} (content, embedding, metadata)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    \"\"\",\n",
    "                    (text, emb, psycopg2.extras.Json(meta)),\n",
    "                )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def similarity_search(self, query: str, k: int = 4,\n",
    "                          filter: Optional[Dict[str, Any]] = None) -> List[Document]:\n",
    "        \n",
    "        query_emb = self.embedding_fn.embed_query(query)\n",
    "        \n",
    "        # 쿼리 매개변수 리스트 초기화. 필터 매개변수가 있다면 여기에 먼저 추가됩니다.\n",
    "        params = []\n",
    "        \n",
    "        # SQL 쿼리 기본 구조 설정\n",
    "        sql_query_template = f\"\"\"\n",
    "            SELECT content, metadata\n",
    "            FROM {self.table}\n",
    "        \"\"\"\n",
    "        \n",
    "        # WHERE 절을 위한 리스트\n",
    "        where_clauses = []\n",
    "        \n",
    "        if filter:\n",
    "            # 1. 필터 딕셔너리를 JSON 문자열로 변환합니다.\n",
    "            filter_json = json.dumps(filter)\n",
    "            \n",
    "            # 2. WHERE 절에 'metadata @> %s::jsonb' 조건을 추가합니다.\n",
    "            where_clauses.append(\"metadata @> %s::jsonb\")\n",
    "            \n",
    "            # 3. 필터 JSON 문자열을 params 리스트에 먼저 추가합니다.\n",
    "            #    이것이 SQL 쿼리에서 가장 먼저 나오는 %s에 바인딩됩니다.\n",
    "            params.append(filter_json)\n",
    "\n",
    "        if where_clauses:\n",
    "            sql_query_template += \" WHERE \" + \" AND \".join(where_clauses)\n",
    "        \n",
    "        # ORDER BY 및 LIMIT 절 추가\n",
    "        # ORDER BY에는 임베딩 비교가 들어가며, 이는 필터가 있든 없든 항상 두 번째 (혹은 첫 번째) %s가 됩니다.\n",
    "        sql_query_template += \"\"\"\n",
    "            ORDER BY embedding <-> %s::vector\n",
    "            LIMIT %s\n",
    "        \"\"\"\n",
    "        \n",
    "        # 4. 임베딩 벡터를 params에 추가합니다.\n",
    "        #    이는 ORDER BY의 %s에 바인딩됩니다.\n",
    "        params.append(query_emb)\n",
    "        \n",
    "        # 5. LIMIT 값 (k)을 params에 마지막으로 추가합니다.\n",
    "        #    이는 LIMIT의 %s에 바인딩됩니다.\n",
    "        params.append(k)\n",
    "        \n",
    "        # 최종 SQL 쿼리: (필터가 있을 경우) WHERE [조건] ORDER BY [임베딩] LIMIT [k]\n",
    "        \n",
    "        with self.conn.cursor() as cur:\n",
    "            # 쿼리와 매개변수를 실행\n",
    "            # 매개변수의 순서는 SQL 쿼리에 나타나는 %s의 순서와 정확히 일치해야 합니다.\n",
    "            cur.execute(sql_query_template, tuple(params))\n",
    "            rows = self.__get_unique_documents(cur.fetchall())\n",
    "\n",
    "        return [Document(page_content=row[0], metadata=row[1]) for row in rows]\n",
    "\n",
    "\n",
    "    def similarity_search_with_score(\n",
    "        self, query: str, k: int = 4\n",
    "    ) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"쿼리와 유사도 점수를 함께 반환\"\"\"\n",
    "        query_emb = self.embedding_fn.embed_query(query)\n",
    "\n",
    "        with self.conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                f\"\"\"\n",
    "                SELECT content, metadata, (embedding <-> %s::vector) AS score\n",
    "                FROM {self.table}\n",
    "                ORDER BY score\n",
    "                LIMIT %s\n",
    "                \"\"\",\n",
    "                (query_emb, k),\n",
    "            )\n",
    "            rows = self.__get_unique_documents(cur.fetchall())\n",
    "            \n",
    "\n",
    "        return [\n",
    "            (Document(page_content=row[0], metadata=row[1]), float(row[2]))\n",
    "            for row in rows\n",
    "        ]\n",
    "    \n",
    "    def __get_unique_documents(self, rows):\n",
    "        # 중복 제거를 위한 후처리\n",
    "        unique_contents = set()\n",
    "        unique_documents = []\n",
    "        \n",
    "        for row in rows:\n",
    "            content = row[0]\n",
    "            metadata = row[1]\n",
    "            \n",
    "            if content not in unique_contents:\n",
    "                unique_contents.add(content)\n",
    "                unique_documents.append(row) # 중복이 아닐 때 원본 튜플을 저장\n",
    "\n",
    "        return unique_documents # 중복 제거된 리스트 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3128d59",
   "metadata": {},
   "source": [
    "### PGVector 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6507b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pgvector_store(connection_string, collection_name, embeddings):\n",
    "    \"\"\"PGVector 스토어 생성\"\"\"\n",
    "    try:\n",
    "        vectorstore = CustomPGVector(\n",
    "            conn_str=connection_string,\n",
    "            embedding_fn=embeddings,\n",
    "            table=collection_name, # 테이블 이름과 매칭\n",
    "        )\n",
    "        print(f\"PGVector 스토어 '{collection_name}'이 생성되었습니다.\")\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        print(f\"PGVector 스토어 생성 중 오류: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c6c541",
   "metadata": {},
   "source": [
    "### 임베딩 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb45564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc94121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64309f0",
   "metadata": {},
   "source": [
    "### PGVector 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3e86ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGVector 스토어 'documents'이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = \"documents\"\n",
    "\n",
    "vectorstore = create_pgvector_store(CONNECTION_STRING, COLLECTION_NAME, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc1713",
   "metadata": {},
   "source": [
    "## 5. 데이터 저장 및 검색\n",
    "\n",
    "pgvector를 사용하여 문서를 저장하고 검색하는 방법을 알아보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221dc2c8",
   "metadata": {},
   "source": [
    "### 샘플 문서 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bba404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 문서 4개가 준비되었습니다.\n",
      "1. 인공지능은 인간의 지능을 모방하는 기술입니다.... (카테고리: AI)\n",
      "2. 머신러닝은 데이터로부터 패턴을 학습하는 AI의 한 분야... (카테고리: ML)\n",
      "3. 딥러닝은 신경망을 사용하는 머신러닝의 하위 분야입니다.... (카테고리: DL)\n",
      "4. 자연어처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 ... (카테고리: NLP)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_documents = [\n",
    "    Document(\n",
    "        page_content=\"인공지능은 인간의 지능을 모방하는 기술입니다.\",\n",
    "        metadata={\"category\": \"AI\", \"topic\": \"기본개념\", \"source\": \"ai_basics.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"머신러닝은 데이터로부터 패턴을 학습하는 AI의 한 분야입니다.\",\n",
    "        metadata={\"category\": \"ML\", \"topic\": \"학습방법\", \"source\": \"ml_intro.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"딥러닝은 신경망을 사용하는 머신러닝의 하위 분야입니다.\",\n",
    "        metadata={\"category\": \"DL\", \"topic\": \"신경망\", \"source\": \"dl_guide.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"자연어처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "        metadata={\"category\": \"NLP\", \"topic\": \"언어처리\", \"source\": \"nlp_handbook.txt\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"샘플 문서 {len(sample_documents)}개가 준비되었습니다.\")\n",
    "for i, doc in enumerate(sample_documents, 1):\n",
    "    print(f\"{i}. {doc.page_content[:30]}... (카테고리: {doc.metadata['category']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167ec7a",
   "metadata": {},
   "source": [
    "### 문서를 벡터스토어에 추가하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "39e75817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_documents_to_pgvector(vectorstore, documents):\n",
    "    \"\"\"문서를 PGVector에 추가\"\"\"\n",
    "    try:\n",
    "        # add_documents 메서드로 문서 추가\n",
    "        vectorstore.add_documents(documents)\n",
    "        print(f\"{len(documents)}개 문서가 성공적으로 추가되었습니다.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"문서 추가 중 오류 발생: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3e8c8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4개 문서가 성공적으로 추가되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "add_documents_to_pgvector(vectorstore, sample_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f34ea",
   "metadata": {},
   "source": [
    "### 벡터 검색 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34784598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def similarity_search_example(vectorstore, query, k=3):\n",
    "    \"\"\"유사도 검색 예제\"\"\"\n",
    "    try:\n",
    "        # 기본 유사도 검색\n",
    "        results = vectorstore.similarity_search(query, k=k)\n",
    "        \n",
    "        print(f\"검색 쿼리: '{query}'\")\n",
    "        print(f\"검색 결과 ({len(results)}개):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, doc in enumerate(results, 1):\n",
    "            print(f\"{i}. {doc.page_content}\")\n",
    "            print(f\"   메타데이터: {doc.metadata}\")\n",
    "            print()\n",
    "            \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"검색 중 오류 발생: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "575fc249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 쿼리: '신경망에 대해 알려주세요'\n",
      "검색 결과 (2개):\n",
      "--------------------------------------------------\n",
      "1. 딥러닝은 신경망을 사용하는 머신러닝의 하위 분야입니다.\n",
      "   메타데이터: {'topic': '신경망', 'source': 'dl_guide.txt', 'category': 'DL'}\n",
      "\n",
      "2. 자연어처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\n",
      "   메타데이터: {'topic': '언어처리', 'source': 'nlp_handbook.txt', 'category': 'NLP'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'topic': '신경망', 'source': 'dl_guide.txt', 'category': 'DL'}, page_content='딥러닝은 신경망을 사용하는 머신러닝의 하위 분야입니다.'),\n",
       " Document(metadata={'topic': '언어처리', 'source': 'nlp_handbook.txt', 'category': 'NLP'}, page_content='자연어처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_search_example(vectorstore, \"신경망에 대해 알려주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f763c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search_with_score_example(vectorstore, query, k=3):\n",
    "    \"\"\"유사도 점수와 함께 검색\"\"\"\n",
    "    try:\n",
    "        # 유사도 점수와 함께 검색\n",
    "        results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "        \n",
    "        print(f\"검색 쿼리: '{query}' (점수 포함)\")\n",
    "        print(f\"검색 결과 ({len(results)}개):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, (doc, score) in enumerate(results, 1):\n",
    "            print(f\"{i}. {doc.page_content}\")\n",
    "            print(f\"   유사도 점수: {score:.4f}\")\n",
    "            print(f\"   메타데이터: {doc.metadata}\")\n",
    "            print()\n",
    "            \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"검색 중 오류 발생: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7a2ea662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 쿼리: '인공지능 기술' (점수 포함)\n",
      "검색 결과 (2개):\n",
      "--------------------------------------------------\n",
      "1. 인공지능은 인간의 지능을 모방하는 기술입니다.\n",
      "   유사도 점수: 0.6897\n",
      "   메타데이터: {'topic': '기본개념', 'source': 'ai_basics.txt', 'category': 'AI'}\n",
      "\n",
      "2. 머신러닝은 데이터로부터 패턴을 학습하는 AI의 한 분야입니다.\n",
      "   유사도 점수: 1.1118\n",
      "   메타데이터: {'topic': '학습방법', 'source': 'ml_intro.txt', 'category': 'ML'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'topic': '기본개념', 'source': 'ai_basics.txt', 'category': 'AI'}, page_content='인공지능은 인간의 지능을 모방하는 기술입니다.'),\n",
       "  0.6896832652063515),\n",
       " (Document(metadata={'topic': '학습방법', 'source': 'ml_intro.txt', 'category': 'ML'}, page_content='머신러닝은 데이터로부터 패턴을 학습하는 AI의 한 분야입니다.'),\n",
       "  1.1117968919839938)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_search_with_score_example(vectorstore, \"인공지능 기술\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b65731",
   "metadata": {},
   "source": [
    "## 6. 고급 검색 기능\n",
    "\n",
    "pgvector의 고급 검색 기능들을 알아보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0283e",
   "metadata": {},
   "source": [
    "### 메타데이터 필터링 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10264150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filtered_search_example(vectorstore, query, filter_dict, k=3):\n",
    "    \"\"\"메타데이터로 필터링된 검색\"\"\"\n",
    "    try:\n",
    "        # 메타데이터 필터를 사용한 검색\n",
    "        results = vectorstore.similarity_search(\n",
    "            query, \n",
    "            k=k,\n",
    "            filter=filter_dict\n",
    "        )\n",
    "        \n",
    "        print(f\"검색 쿼리: '{query}'\")\n",
    "        print(f\"필터 조건: {filter_dict}\")\n",
    "        print(f\"검색 결과 ({len(results)}개):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, doc in enumerate(results, 1):\n",
    "            print(f\"{i}. {doc.page_content}\")\n",
    "            print(f\"   메타데이터: {doc.metadata}\")\n",
    "            print()\n",
    "            \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"필터링 검색 중 오류 발생: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1445d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 쿼리: '인공지능'\n",
      "필터 조건: {'category': 'AI'}\n",
      "검색 결과 (2개):\n",
      "--------------------------------------------------\n",
      "1. 인공지능은 인간의 지능을 모방하는 기술입니다.\n",
      "   메타데이터: {'topic': '기본개념', 'source': 'ai_basics.txt', 'category': 'AI'}\n",
      "\n",
      "2. 인공지능은 인간의 지능을 모방하는 기술입니다.\n",
      "   메타데이터: {'topic': '기본개념', 'source': 'ai_basics.txt', 'category': 'AI'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'topic': '기본개념', 'source': 'ai_basics.txt', 'category': 'AI'}, page_content='인공지능은 인간의 지능을 모방하는 기술입니다.'),\n",
       " Document(metadata={'topic': '기본개념', 'source': 'ai_basics.txt', 'category': 'AI'}, page_content='인공지능은 인간의 지능을 모방하는 기술입니다.')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_search_example(vectorstore, \"인공지능\", {\"category\": \"AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5358895",
   "metadata": {},
   "source": [
    "### 하이브리드 검색 (벡터 + 키워드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "583094bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hybrid_search_example(vectorstore, query, k=3):\n",
    "    \"\"\"하이브리드 검색 예제\"\"\"\n",
    "    try:\n",
    "        # 1. 벡터 검색\n",
    "        vector_results = vectorstore.similarity_search(query, k=k)\n",
    "        \n",
    "        # 2. 키워드 검색 (PostgreSQL의 텍스트 검색 기능 활용)\n",
    "        # 실제로는 SQL 쿼리를 직접 실행해야 함\n",
    "        print(\"하이브리드 검색 결과:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(\"벡터 검색 결과:\")\n",
    "        for i, doc in enumerate(vector_results, 1):\n",
    "            print(f\"{i}. {doc.page_content}\")\n",
    "            print(f\"   메타데이터: {doc.metadata}\")\n",
    "            print()\n",
    "            \n",
    "        return vector_results\n",
    "    except Exception as e:\n",
    "        print(f\"하이브리드 검색 중 오류 발생: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1afee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하이브리드 검색 결과:\n",
      "==================================================\n",
      "벡터 검색 결과:\n",
      "1. 머신러닝은 데이터로부터 패턴을 학습하는 AI의 한 분야입니다.\n",
      "   메타데이터: {'topic': '학습방법', 'source': 'ml_intro.txt', 'category': 'ML'}\n",
      "\n",
      "2. 머신러닝은 데이터로부터 패턴을 학습하는 AI의 한 분야입니다.\n",
      "   메타데이터: {'topic': '학습방법', 'source': 'ml_intro.txt', 'category': 'ML'}\n",
      "\n",
      "3. 딥러닝은 신경망을 사용하는 머신러닝의 하위 분야입니다.\n",
      "   메타데이터: {'topic': '신경망', 'source': 'dl_guide.txt', 'category': 'DL'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'topic': '학습방법', 'source': 'ml_intro.txt', 'category': 'ML'}, page_content='머신러닝은 데이터로부터 패턴을 학습하는 AI의 한 분야입니다.'),\n",
       " Document(metadata={'topic': '학습방법', 'source': 'ml_intro.txt', 'category': 'ML'}, page_content='머신러닝은 데이터로부터 패턴을 학습하는 AI의 한 분야입니다.'),\n",
       " Document(metadata={'topic': '신경망', 'source': 'dl_guide.txt', 'category': 'DL'}, page_content='딥러닝은 신경망을 사용하는 머신러닝의 하위 분야입니다.')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_search_example(vectorstore, \"머신러닝 학습\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d8fd9",
   "metadata": {},
   "source": [
    "## 7. 실제 파일을 사용한 예제\n",
    "실제 텍스트 파일을 로드하여 pgvector에 저장하고 검색하는 완전한 예제를 만들어보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d7f42",
   "metadata": {},
   "source": [
    "### 텍스트 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "544950d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 로드 완료: 1개 문서\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    loader = TextLoader(\"./data/rag-keywords.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    print(f\"파일 로드 완료: {len(documents)}개 문서\")\n",
    "except FileNotFoundError:\n",
    "    print(\"rag-keywords.txt 파일을 찾을 수 없습니다. 샘플 데이터를 사용합니다.\")\n",
    "    documents = sample_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a0c364",
   "metadata": {},
   "source": [
    "### 텍스트 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d0e7ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 분할 완료: 41개 청크\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"텍스트 분할 완료: {len(splits)}개 청크\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9185d",
   "metadata": {},
   "source": [
    "### 임베딩 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d83c27",
   "metadata": {},
   "source": [
    "### PGVector 스토어 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c22dd5",
   "metadata": {},
   "source": [
    "#### 자동으로 생성되는 테이블들\n",
    "> collection_name=\"my_collection\" 이라고 하면, 내부적으로 컬렉션 관리용 메타 테이블과 데이터 저장 테이블이 만들어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b926a",
   "metadata": {},
   "source": [
    "- 컬렉션 관리 테이블\n",
    "    ```sql\n",
    "    CREATE TABLE langchain_pg_collection (\n",
    "        uuid UUID PRIMARY KEY,          -- 컬렉션 고유 ID\n",
    "        name TEXT UNIQUE,               -- collection_name (예: \"my_collection\")\n",
    "        cmetadata JSONB                 -- 컬렉션 메타데이터 (옵션)\n",
    "    );\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558d5c6",
   "metadata": {},
   "source": [
    "- 벡터 + 문서 저장 테이블\n",
    "    ```sql\n",
    "    CREATE TABLE langchain_pg_embedding (\n",
    "        uuid UUID PRIMARY KEY,          -- 각 문서 벡터의 고유 ID\n",
    "        collection_id UUID NOT NULL,    -- 어떤 컬렉션에 속하는지 (FK: langchain_pg_collection.uuid)\n",
    "        embedding VECTOR(1536),         -- pgvector 타입 (차원은 임베딩 모델에 따라 다름)\n",
    "        document TEXT,                  -- 원문 텍스트 (Document.page_content)\n",
    "        metadata JSONB,                 -- 문서 메타데이터 (Document.metadata)\n",
    "        cmetadata JSONB                 -- 내부적으로 쓰이는 추가 메타데이터\n",
    "    );\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf32ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyoungwon-cho/dev/github/inflearn_LLM/2. RAG/Langchain/2. Advanced RAG/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/pgvector.py:490: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  store = cls(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "vectorstore = PGVector.from_documents(\n",
    "    documents=splits, # 분할된 문서 사용\n",
    "    embedding=embeddings, # 임베딩 함수\n",
    "    connection_string=CONNECTION_STRING, # PostgreSQL 연결 문자열\n",
    "    collection_name=\"rag_keywords\", # 테이블 이름\n",
    "    distance_strategy=DistanceStrategy.COSINE, # 코사인 유사도 사용\n",
    "    pre_delete_collection=False, # 기존 테이블 삭제 여부\n",
    "    use_jsonb=True, # 메타데이터를 JSONB로 저장 (더 나은 성능과 유연성 제공)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be090f",
   "metadata": {},
   "source": [
    "### 질문 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f05e85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, k=3):\n",
    "    # 유사도 검색\n",
    "    return vectorstore.similarity_search(query, k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9312f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, k=3):\n",
    "    # 질문에 대한 답변 생성\n",
    "    docs = search_documents(question, k)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # 실제로는 LLM을 사용하여 답변 생성\n",
    "    return f\"질문: {question}\\n관련 문서: {context}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32d5a663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 인공지능이란 무엇인가요?\n",
      "관련 문서: 연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\n",
      "연관키워드: 데이터 융합, 인공지능, 딥러닝\n",
      "Deep Learning\n",
      "\n",
      "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
      "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
      "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
      "\n",
      "Schema\n"
     ]
    }
   ],
   "source": [
    "answer = answer_question(\"인공지능이란 무엇인가요?\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
